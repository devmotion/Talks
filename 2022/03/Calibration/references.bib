@article{Cooke1906B,
  doi = {10.1175/1520-0493(1906)34<274b:wf>2.0.co;2},
  url = {https://doi.org/10.1175/1520-0493(1906)34<274b:wf>2.0.co;2},
  year = {1906},
  month = jun,
  publisher = {American Meteorological Society},
  volume = {34},
  number = {6},
  pages = {274--275},
  title = {Weighting forecasts},
  author = {Ernest Cooke},
  journal = {Monthly Weather Review}
}

@InProceedings{Vaicenavicius2019,
  title = {Evaluating model calibration in classification},
  author = {Vaicenavicius, Juozas and Widmann, David and Andersson, Carl and Lindsten, Fredrik and Roll, Jacob and Sch\"{o}n, Thomas},
  booktitle = {Proceedings of the Twenty-Second International Conference on Artificial Intelligence and Statistics},
  year = {2019},
  volume = {89},
  month = {04},
  pdf = {http://proceedings.mlr.press/v89/vaicenavicius19a/vaicenavicius19a.pdf},
  url = {https://proceedings.mlr.press/v89/vaicenavicius19a.html},
  abstract = {Probabilistic classifiers output a probability distribution on target classes rather than just a class prediction. Besides providing a clear separation of prediction and decision making, the main advantage of probabilistic models is their ability to represent uncertainty about predictions. In safety-critical applications, it is pivotal for a model to possess an adequate sense of uncertainty, which for probabilistic classifiers translates into outputting probability distributions that are consistent with the empirical frequencies observed from realized outcomes. A classifier with such a property is called calibrated. In this work, we develop a general theoretical calibration evaluation framework grounded in probability theory, and point out subtleties present in model calibration evaluation that lead to refined interpretations of existing evaluation techniques. Lastly, we propose new ways to quantify and visualize miscalibration in probabilistic classification, including novel multidimensional reliability diagrams.}
}

@InProceedings{Widmann2019,
  title = {Calibration tests in multi-class classification: A unifying framework},
  shorttitle = {Calibration tests in multi-class classification},
  author = {Widmann, David and Lindsten, Fredrik and Zachariah, Dave},
  booktitle = {Advances in Neural Information Processing Systems 32},
  year = {2019},
  url = {http://papers.nips.cc/paper/9392-calibration-tests-in-multi-class-classification-a-unifying-framework.pdf}
}

@inproceedings{Widmann2021,
  title={Calibration tests beyond classification},
  author={David Widmann and Fredrik Lindsten and Dave Zachariah},
  booktitle={International Conference on Learning Representations},
  year={2021},
  url={https://openreview.net/forum?id=-bxf89v3Nx}
}

@article{Gorman2014,
  doi = {10.1371/journal.pone.0090081},
  url = {https://doi.org/10.1371/journal.pone.0090081},
  year = {2014},
  month = {03},
  publisher = {Public Library of Science ({PLoS})},
  volume = {9},
  number = {3},
  pages = {e90081},
  author = {Kristen B. Gorman and Tony D. Williams and William R. Fraser},
  title = {Ecological Sexual Dimorphism and Environmental Variability within a Community of Antarctic Penguins (Genus Pygoscelis)},
  journal = {{PLoS} {ONE}}
}

@book{Villani2009,
  doi = {10.1007/978-3-540-71050-9},
  url = {https://doi.org/10.1007/978-3-540-71050-9},
  year = {2009},
  publisher = {Springer Berlin Heidelberg},
  author = {C{\'{e}}dric Villani},
  title = {Optimal Transport}
}

@article{Broecker2007,
  author = {Jochen Br{\"o}cker and Leonard A. Smith},
  title = {Increasing the reliability of reliability diagrams},
  journal = {Weather and Forecasting},
  year = {2007},
}

@article{Broecker2009,
  doi = {10.1002/qj.456},
  url = {https://doi.org/10.1002/qj.456},
  year = {2009},
  month = jul,
  publisher = {Wiley},
  volume = {135},
  number = {643},
  author = {Jochen Br\"{o}cker},
  title = {Reliability, sufficiency, and the decomposition of proper scores},
  journal = {Quarterly Journal of the Royal Meteorological Society}
}
